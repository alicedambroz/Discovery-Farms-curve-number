{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWBh6aBTI4ryzBHWhJY+dC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicedambroz/Discovery-Farms-curve-number/blob/main/Discovery_Farms_Curve_Number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use this code to estimate Curve Number from flow and precipitation data**\n",
        "\n",
        "Data files contain 3 spreadsheets per site. Those include Precipitation, Runoff and Events.\n",
        "\n",
        "1.   **Precipitation** = minute interval rainfall data in inches and milimiters.\n",
        "2.   **Runoff** = minute interval discharge in cfs was transformed to volume in milimiters.\n",
        "3.   **Events** = start and end date and time of each event, as separated in Discovery Farms original files.\n",
        "\n",
        "Sites under analysis here are: Redwood South (no-till without cover crops), Redwood North (no-till with cover crops after 2021) and McLeod (conventional tillage).\n",
        "\n",
        "*Calculations are run on the metric system.*\n",
        "\n",
        "\n",
        "**To run code:**\n",
        "*   Get data files and save them as Google Sheets on Google Drive. Use URL code in sites_config"
      ],
      "metadata": {
        "id": "LLRzSdIh3iF1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debpsSRVT0Nd"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth, files\n",
        "from google.auth import default\n",
        "import gspread\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Batch run for RWS, RWN and MC"
      ],
      "metadata": {
        "id": "lKIiSeZEOofs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPEN DATA\n",
        "# From Google Sheets, paste URL from each site's file\n",
        "\n",
        "sites_config = {\n",
        "    'MC1':  '152H5O0QNSPoVYDgHuSD8Tq7C4rWKppXwhh8TSeP1DsY',   #spreadsheet ID here\n",
        "    'RW1N': '1wbd9KU4-aVSgwU39b-P8cs9UeREUWwNGzooJYV5GLRk',  #spreadsheet ID here\n",
        "    'RW1S': '10kwU-3ZJ1lkK-5dymXfjpI-Zz2tE-1cqnVVSo-Y_SBE' #spreadsheet ID here\n",
        "}\n",
        "\n",
        "# PROCESS DATA\n",
        "# Functions to configure data\n",
        "\n",
        "\n",
        "def process_site_data(site_name, sheet_id):\n",
        "    print(f\"Processing Site: {site_name}...\")\n",
        "\n",
        "    try:\n",
        "        spreadsheet = gc.open_by_key(sheet_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet for {site_name}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get data from each spreadsheet\n",
        "    sheet_p = spreadsheet.worksheet(\"Precipitation\")\n",
        "    rows_p = sheet_p.get_all_values()\n",
        "    df_p = pd.DataFrame(rows_p[1:], columns=rows_p[0])\n",
        "\n",
        "    sheet_q = spreadsheet.worksheet(\"Runoff\")\n",
        "    rows_q = sheet_q.get_all_values()\n",
        "    df_q = pd.DataFrame(rows_q[1:], columns=rows_q[0])\n",
        "\n",
        "    sheet_ev = spreadsheet.worksheet(\"Events\")\n",
        "    rows_ev = sheet_ev.get_all_values()\n",
        "    df_events_meta = pd.DataFrame(rows_ev[1:], columns=rows_ev[0])\n",
        "\n",
        "    # Clean and transform data\n",
        "    # Precipitation\n",
        "    df_p['Rainfall_mm'] = pd.to_numeric(df_p['Rainfall_mm'], errors='coerce').fillna(0)\n",
        "    df_p['Date'] = pd.to_datetime(df_p['Date'], format='mixed', dayfirst=False)\n",
        "\n",
        "    # Runoff\n",
        "    df_q['Volume_mm'] = pd.to_numeric(df_q['Volume_mm'], errors='coerce').fillna(0)\n",
        "    df_q['Event'] = pd.to_numeric(df_q['Event'], errors='coerce').fillna(0)\n",
        "    df_q['Date'] = pd.to_datetime(df_q['Date'], format='mixed', dayfirst=False)\n",
        "\n",
        "    # Events\n",
        "    df_events_meta['Event'] = pd.to_numeric(df_events_meta['Event'], errors='coerce')\n",
        "    df_events_meta['Start'] = pd.to_datetime(df_events_meta['Start'], format='mixed', dayfirst=False)\n",
        "    df_events_meta['End'] = pd.to_datetime(df_events_meta['End'], format='mixed', dayfirst=False)\n",
        "\n",
        "    # Frozen and nonfrozen events\n",
        "    # Clean 'Frozen' column and convert to string\n",
        "    if 'Frozen' in df_events_meta.columns:\n",
        "        df_events_meta['Frozen'] = df_events_meta['Frozen'].astype(str)\n",
        "    else:\n",
        "        df_events_meta['Frozen'] = 'Unknown'\n",
        "\n",
        "    df_events_meta = df_events_meta[df_events_meta['Event'] > 0].copy()\n",
        "\n",
        "    # Creates master timeline of 1-minute interval\n",
        "    min_date = min(df_p['Date'].min(), df_q['Date'].min())\n",
        "    max_date = max(df_p['Date'].max(), df_q['Date'].max())\n",
        "    time_index = pd.date_range(start=min_date, end=max_date, freq='1min')\n",
        "    df_master = pd.DataFrame({'Date': time_index})\n",
        "\n",
        "    # Merge precipitation and runoff data with master timeline dataframe\n",
        "    df_master = df_master.merge(df_q[['Date', 'Volume_mm']], on='Date', how='left')\n",
        "    df_master = df_master.merge(df_p[['Date', 'Rainfall_mm']], on='Date', how='left')\n",
        "    df_master['Volume_mm'] = df_master['Volume_mm'].fillna(0)\n",
        "    df_master['Rainfall_mm'] = df_master['Rainfall_mm'].fillna(0)\n",
        "\n",
        "    # Extract events\n",
        "    site_events_list = []\n",
        "\n",
        "    for _, ev in df_events_meta.iterrows():\n",
        "        event_id = ev['Event']\n",
        "        start_flow = ev['Start']\n",
        "        end_flow = ev['End']\n",
        "        frozen_status = ev['Frozen'] #'Frozen' status\n",
        "\n",
        "        if pd.isna(start_flow) or pd.isna(end_flow):\n",
        "            continue\n",
        "\n",
        "        start_plot = start_flow - pd.Timedelta(hours=6)\n",
        "\n",
        "        mask = (df_master['Date'] >= start_plot) & (df_master['Date'] <= end_flow)\n",
        "        df_event_slice = df_master.loc[mask].copy()\n",
        "\n",
        "        df_event_slice['Event'] = event_id\n",
        "        df_event_slice['Site'] = site_name\n",
        "        df_event_slice['Frozen'] = frozen_status\n",
        "\n",
        "        site_events_list.append(df_event_slice)\n",
        "\n",
        "    if site_events_list:\n",
        "        return pd.concat(site_events_list, ignore_index=True)\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# FINAL DATAFRAME\n",
        "# Get merged and organized data ready for plotting and for calculating CN\n",
        "\n",
        "all_sites_data = []\n",
        "\n",
        "# Loop through the site dictionary defined previously\n",
        "for site, sheet_id in sites_config.items():\n",
        "    df_site = process_site_data(site, sheet_id)\n",
        "    if not df_site.empty:\n",
        "        all_sites_data.append(df_site)\n",
        "\n",
        "# Concatenate all sites data into one final dataframe\n",
        "if all_sites_data:\n",
        "    df_final = pd.concat(all_sites_data, ignore_index=True)\n",
        "\n",
        "    # Preview\n",
        "    print(\"\\nProcessing Complete!\")\n",
        "    print(df_final.head())\n",
        "    print(f\"Total rows: {len(df_final)}\")\n",
        "\n",
        "    # Save and download\n",
        "    df_final.to_csv('All_Sites_Events_Plotting.csv', index=False)\n",
        "    files.download('All_Sites_Events_Plotting.csv')\n",
        "else:\n",
        "    print(\"No data processed.\")\n",
        "\n",
        "# This dataframe can now be used in R for plotting each hydrograph!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "AXOpfRM1OuBK",
        "outputId": "ecfed4e1-8717-4796-a79d-cbd0c6614253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Site: MC1...\n",
            "Processing Site: RW1N...\n",
            "Processing Site: RW1S...\n",
            "\n",
            "Processing Complete!\n",
            "                 Date  Volume_mm  Rainfall_mm  Event Site  Frozen\n",
            "0 2017-02-15 07:14:00        0.0          0.0      1  MC1  frozen\n",
            "1 2017-02-15 07:15:00        0.0          0.0      1  MC1  frozen\n",
            "2 2017-02-15 07:16:00        0.0          0.0      1  MC1  frozen\n",
            "3 2017-02-15 07:17:00        0.0          0.0      1  MC1  frozen\n",
            "4 2017-02-15 07:18:00        0.0          0.0      1  MC1  frozen\n",
            "Total rows: 273363\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05c2c3ea-3045-40e6-ae46-ecb3c56d6bb3\", \"All_Sites_Events_Plotting.csv\", 13747603)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CALCULATE S AND CN\n",
        "# Final dataframe from previous chunk can now be used to calculate S and CN\n",
        "\n",
        "\n",
        "print(\"Calculating Curve Numbers...\")\n",
        "\n",
        "# GROUP INFO\n",
        "# Group information from each event and each site to calculate precipitation and runoff volume totals, maintaining 'Frozen' status\n",
        "summary = df_final.groupby(['Site', 'Event', 'Frozen']).agg(\n",
        "    Start_Time=('Date', 'min'),\n",
        "    End_Time=('Date', 'max'),\n",
        "    Total_Rainfall_mm=('Rainfall_mm', 'sum'),\n",
        "    Total_Runoff_mm=('Volume_mm', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# S AND CN FUNCTIONS\n",
        "def calculate_S(P, Q):\n",
        "    # Formula to estimate S:\n",
        "    # S = 5 * (P + 2Q - sqrt(4Q^2 + 5PQ))\n",
        "          # P and Q are in mm.\n",
        "          # For P >= Q! If Q > P, some error...\n",
        "\n",
        "    if Q <= 0:\n",
        "        return np.nan # If runoff is 0, we can assume all precipitation was stored\n",
        "    if Q >= P:\n",
        "        return 0 # If runoff is greater than precipitation, we can assume saturation, S=0, or some type of data error\n",
        "\n",
        "    term1 = P + (2 * Q)\n",
        "    term2 = np.sqrt((4 * (Q**2)) + (5 * P * Q))\n",
        "    S = 5 * (term1 - term2)\n",
        "    return S\n",
        "\n",
        "def calculate_CN(S):\n",
        "    if pd.isna(S):\n",
        "        return np.nan\n",
        "    # Formula to estimate CN in the metric system:\n",
        "    # CN = 25400 / (S + 254)\n",
        "    return 25400 / (S + 254)\n",
        "\n",
        "# CALCULATE S AND CN\n",
        "summary['S_mm'] = summary.apply(\n",
        "    lambda row: calculate_S(row['Total_Rainfall_mm'], row['Total_Runoff_mm']), axis=1\n",
        ")\n",
        "\n",
        "summary['CN'] = summary['S_mm'].apply(calculate_CN)\n",
        "\n",
        "# To clean and round decimals\n",
        "summary['Total_Rainfall_mm'] = summary['Total_Rainfall_mm'].round(4)\n",
        "summary['Total_Runoff_mm'] = summary['Total_Runoff_mm'].round(4)\n",
        "summary['S_mm'] = summary['S_mm'].round(4)\n",
        "summary['CN'] = summary['CN'].round(4)\n",
        "\n",
        "# Sort data per site and event number\n",
        "summary = summary.sort_values(by=['Site', 'Event'])\n",
        "\n",
        "# Check output\n",
        "print(\"\\nCalculation Complete! Preview:\")\n",
        "print(summary.head())\n",
        "\n",
        "# Save and download\n",
        "summary.to_csv('Event_Summary_CN_S.csv', index=False)\n",
        "files.download('Event_Summary_CN_S.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "EJJVW4yAYmfZ",
        "outputId": "0993d535-6fdc-4f8f-a67b-d0efc555ad49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Curve Numbers...\n",
            "\n",
            "Calculation Complete! Preview:\n",
            "  Site  Event     Frozen          Start_Time            End_Time  \\\n",
            "0  MC1      1     frozen 2017-02-15 07:14:00 2017-02-18 17:16:00   \n",
            "1  MC1      2  nonfrozen 2017-04-14 23:00:00 2017-04-15 08:23:00   \n",
            "2  MC1      3  nonfrozen 2017-04-19 09:24:00 2017-04-19 20:00:00   \n",
            "3  MC1      4  nonfrozen 2017-04-30 15:00:00 2017-05-01 09:30:00   \n",
            "4  MC1      5  nonfrozen 2017-05-16 19:46:00 2017-05-18 00:10:00   \n",
            "\n",
            "   Total_Rainfall_mm  Total_Runoff_mm      S_mm        CN  \n",
            "0              0.000           1.4416    0.0000  100.0000  \n",
            "1             25.146           0.0081  120.7776   67.7735  \n",
            "2             20.828           0.0136   98.3187   72.0938  \n",
            "3             31.750           0.0391  146.6791   63.3924  \n",
            "4             31.750           0.6395  114.3631   68.9537  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6497a57a-e861-4c94-8039-f7325e463f2a\", \"Event_Summary_CN_S.csv\", 17709)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tests: DO NOT RUN"
      ],
      "metadata": {
        "id": "SWCnKyfou1Ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RW NORTH SITE"
      ],
      "metadata": {
        "id": "u3PaIMoikN4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get rainfall data"
      ],
      "metadata": {
        "id": "kznF7E6JT-_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '1LZIpzGVfSbKe9J8NH3sRRE_n26yi4HeRQdapKdx43dQ' #id da planilha do google sheets - retirado do url\n",
        "spreadsheet = gc.open_by_key(id) #para abrir spreadsheet pela chave\n",
        "sheet = spreadsheet.worksheet(\"Precipitation\") #nome da planilha a ser trabalhada\n",
        "rows = sheet.get_all_values()\n",
        "df_p_n = pd.DataFrame(rows[1:]) #transforma em DataFrame, a partir da linha 1 (linha 0 = cabeçalho)\n",
        "df_p_n.columns = rows[0] #para transformar a primeira linha"
      ],
      "metadata": {
        "id": "0Ug7Q7_CT84F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_n.info()"
      ],
      "metadata": {
        "id": "r94QuXi5UFpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_n['Rainfall_mm'] = pd.to_numeric(df_p_n['Rainfall_mm'], errors='coerce') #transformar object em float\n",
        "df_p_n['Rainfall_mm'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_p_n['Date'] = pd.to_datetime(df_p_n['Date'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime"
      ],
      "metadata": {
        "id": "44rNM3eZUHV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_n.info()"
      ],
      "metadata": {
        "id": "B6PG5zevWgCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get runoff data"
      ],
      "metadata": {
        "id": "T-Sl5MfxWx-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '1LZIpzGVfSbKe9J8NH3sRRE_n26yi4HeRQdapKdx43dQ' #id da planilha do google sheets - retirado do url\n",
        "spreadsheet = gc.open_by_key(id) #para abrir spreadsheet pela chave\n",
        "sheet = spreadsheet.worksheet(\"Runoff\") #nome da planilha a ser trabalhada\n",
        "rows = sheet.get_all_values()\n",
        "df_q_n = pd.DataFrame(rows[1:]) #transforma em DataFrame, a partir da linha 1 (linha 0 = cabeçalho)\n",
        "df_q_n.columns = rows[0] #para transformar a primeira linha"
      ],
      "metadata": {
        "id": "zpGSggAoWrtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_n.info()"
      ],
      "metadata": {
        "id": "gW1JRsl6Wrtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_n['Volume_mm'] = pd.to_numeric(df_q_n['Volume_mm'], errors='coerce') #transformar object em float\n",
        "df_q_n['Volume_mm'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_q_n['Event'] = pd.to_numeric(df_q_n['Event'], errors='coerce') #transformar object em float\n",
        "df_q_n['Event'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_q_n['Date'] = pd.to_datetime(df_q_n['Date'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RMdD1bM8Wrtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_n.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7BCD01EMWrtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get start and end of each event"
      ],
      "metadata": {
        "id": "jTHcEffEXVN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events_time_n = (\n",
        "    df_q_n\n",
        "    .groupby('Event')['Date']\n",
        "    .agg(start_time='min', end_time='max')\n",
        "    .reset_index()\n",
        ")"
      ],
      "metadata": {
        "id": "5JAxmL8mXXQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events_time_n = events_time_n[events_time_n['Event'] != 0]"
      ],
      "metadata": {
        "id": "02luVa5AcINx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "events_time_n.to_csv('RW1S_events_start_end.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('RW1S_events_start_end.csv')"
      ],
      "metadata": {
        "id": "uHhx8EZcDRF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Merge precipitation and runoff data on minute interval"
      ],
      "metadata": {
        "id": "YuocFC98Y3k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_index_n = pd.date_range(\n",
        "    start='2016-10-01 00:00:00',\n",
        "    end='2024-09-30 00:00:00',\n",
        "    freq='1min'\n",
        ")\n",
        "\n",
        "df_time_n = pd.DataFrame({'Date': time_index_n})"
      ],
      "metadata": {
        "id": "drWD8nvPZfU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_n = df_time_n.merge(\n",
        "    df_q_n,\n",
        "    on='Date',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "q0d2bm8UZiL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_n = df_master_n.merge(\n",
        "    df_p_n[['Date', 'Rainfall_mm']],\n",
        "    on='Date',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "YF1walrqZ1ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create columns with date and time only"
      ],
      "metadata": {
        "id": "dLOEe4Yzdpzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_n['Date1'] = df_master_n['Date'].dt.date\n",
        "df_master_n['Time'] = df_master_n['Date'].dt.time"
      ],
      "metadata": {
        "id": "uUdGwtWJdhh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separate events"
      ],
      "metadata": {
        "id": "YOt5G7KibNyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_n = df_master_n.sort_values('Date')\n",
        "events_time_n = events_time_n.sort_values('start_time')"
      ],
      "metadata": {
        "id": "yAfbyk8XbNkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_n['Date'] = pd.to_datetime(df_master_n['Date']) #garantir datetime completo\n",
        "\n",
        "df_master_n['date'] = df_master_n['Date'].dt.date\n",
        "df_master_n['is_midnight'] = (\n",
        "    (df_master_n['Date'].dt.hour == 0) &\n",
        "    (df_master_n['Date'].dt.minute == 0)\n",
        ") #criar colunas auxiliares uma única vez"
      ],
      "metadata": {
        "id": "O0_c8TYCdv6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_events_n = []\n",
        "\n",
        "for _, ev in events_time_n.iterrows():\n",
        "\n",
        "    start = ev['start_time']\n",
        "    end = ev['end_time']\n",
        "    event_id = ev['Event']\n",
        "\n",
        "        start_rain = start - pd.Timedelta(hours=6) #para considerar o início da chuva 6 horas antes do início do escoamento\n",
        "\n",
        "    mask_event = (\n",
        "        (df_master_n['Date'] >= start_rain) &\n",
        "        (df_master_n['Date'] <= end)\n",
        "    ) #novo intervalo do evento, considerando a precipitação de 6 horas\n",
        "\n",
        "    df_ev_n = df_master_n.loc[mask_event].copy() #usar .copy() para evitar SettingWithCopy warnings depois\n",
        "\n",
        "    df_ev_n.loc[df_ev_n['Date'] < start, 'Volume_mm'] = 0 #aqui ele vai zerar o escoamento antes da chuva começar: ERRADO!!\n",
        "\n",
        "    days_event_n = pd.date_range(\n",
        "        start_rain.date(),\n",
        "        end.date(),\n",
        "        freq='D'\n",
        "    ).date #para pegar os volumes acumulados quando tem leitura a meia-noite\n",
        "\n",
        "        mask_daily = (\n",
        "        df_master_n['date'].isin(days_event_n) &\n",
        "        df_master_n['is_midnight'] &\n",
        "        df_master_n['Rainfall_mm'].notna()\n",
        "    )\n",
        "    df_daily_n = df_master_n.loc[mask_daily]\n",
        "\n",
        "    df_event_full_n = (\n",
        "        pd.concat([df_ev_n, df_daily_n])\n",
        "        .drop_duplicates(subset='Date')\n",
        "        .sort_values('Date')\n",
        "    ) #aqui vai unir todos os eventos e ordená-los\n",
        "\n",
        "    df_event_full_n = df_event_full_n.copy()\n",
        "    df_event_full_n['Event'] = event_id\n",
        "\n",
        "    dfs_events_n.append(df_event_full_n)"
      ],
      "metadata": {
        "id": "Lfv7dMJ4f03F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_events_ext_n = pd.concat(dfs_events_n, ignore_index=True)"
      ],
      "metadata": {
        "id": "Msa0-Lf8gLYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "df_master_events_ext_n.to_csv('RWN1_events_extended.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('RWN1_events_extended.csv')"
      ],
      "metadata": {
        "id": "xaW9FRvtcfTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sum event variables"
      ],
      "metadata": {
        "id": "zkKOcOkpiaX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_sums_n = (\n",
        "    df_master_events_ext_n\n",
        "    .groupby('Event', as_index=False)\n",
        "    .agg(\n",
        "        Volume_event_mm=('Volume_mm', 'sum'),\n",
        "        Rainfall_event_mm=('Rainfall_mm', 'sum')\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "0YkQpcbYib38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_sums_n[\n",
        "    (event_sums['Rainfall_event_mm'] == 0) |\n",
        "    (event_sums['Volume_event_mm'] == 0)\n",
        "]"
      ],
      "metadata": {
        "id": "lkTmKJ1QifkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minutes_per_event_n = (\n",
        "    df_master_events_ext_n\n",
        "    .groupby('Event')['Date']\n",
        "    .count()\n",
        "    .reset_index(name='n_minutes')\n",
        ")\n",
        "\n",
        "event_sums_n = event_sums_n.merge(minutes_per_event_n, on='Event')"
      ],
      "metadata": {
        "id": "CgDbl40wio9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_sums_n"
      ],
      "metadata": {
        "id": "aQe3ZzEfirzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "event_sums_n.to_csv('RWN1_sums.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('RWN1_sums.csv')"
      ],
      "metadata": {
        "id": "89Gx6M9vi1CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RW SOUTH SITE"
      ],
      "metadata": {
        "id": "DOEKDXbKkZUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get rainfall data"
      ],
      "metadata": {
        "id": "M9uuy7_mkZUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '1AJzpMK6QYbVPqdcseUkIfdKCwBDHttrcKxfWti2iAec' #id da planilha do google sheets - retirado do url\n",
        "spreadsheet = gc.open_by_key(id) #para abrir spreadsheet pela chave\n",
        "sheet = spreadsheet.worksheet(\"Precipitation\") #nome da planilha a ser trabalhada\n",
        "rows = sheet.get_all_values()\n",
        "df_p_s = pd.DataFrame(rows[1:]) #transforma em DataFrame, a partir da linha 1 (linha 0 = cabeçalho)\n",
        "df_p_s.columns = rows[0] #para transformar a primeira linha"
      ],
      "metadata": {
        "id": "RXpeV09DkZUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_s.info()"
      ],
      "metadata": {
        "id": "Me_XlkzwkZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_s['Rainfall_mm'] = pd.to_numeric(df_p_s['Rainfall_mm'], errors='coerce') #transformar object em float\n",
        "df_p_s['Rainfall_mm'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_p_s['Date'] = pd.to_datetime(df_p_s['Date'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime"
      ],
      "metadata": {
        "id": "AGT9K4EUkZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_s.info()"
      ],
      "metadata": {
        "id": "PFmm8uASkZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get runoff data"
      ],
      "metadata": {
        "id": "Iqq0yxD6kZUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '1AJzpMK6QYbVPqdcseUkIfdKCwBDHttrcKxfWti2iAec' #id da planilha do google sheets - retirado do url\n",
        "spreadsheet = gc.open_by_key(id) #para abrir spreadsheet pela chave\n",
        "sheet = spreadsheet.worksheet(\"Runoff\") #nome da planilha a ser trabalhada\n",
        "rows = sheet.get_all_values()\n",
        "df_q_s = pd.DataFrame(rows[1:]) #transforma em DataFrame, a partir da linha 1 (linha 0 = cabeçalho)\n",
        "df_q_s.columns = rows[0] #para transformar a primeira linha"
      ],
      "metadata": {
        "id": "84t4R9ELkZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_s.info()"
      ],
      "metadata": {
        "id": "Fm-QJ4qukZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_s['Volume_mm'] = pd.to_numeric(df_q_s['Volume_mm'], errors='coerce') #transformar object em float\n",
        "df_q_s['Volume_mm'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_q_s['Event'] = pd.to_numeric(df_q_s['Event'], errors='coerce') #transformar object em float\n",
        "df_q_s['Event'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_q_s['Date'] = pd.to_datetime(df_q_s['Date'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5Og2g987kZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_s.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IwSz421TkZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get start and end of each event"
      ],
      "metadata": {
        "id": "xqcd9kqdkZUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events_time_s = (\n",
        "    df_q_s\n",
        "    .groupby('Event')['Date']\n",
        "    .agg(start_time='min', end_time='max')\n",
        "    .reset_index()\n",
        ")"
      ],
      "metadata": {
        "id": "chinKJwakZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events_time_s = events_time_s[events_time_s['Event'] != 0]"
      ],
      "metadata": {
        "id": "zK1hCm3skZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "events_time_s.to_csv('RW1S_events_start_end.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('RW1S_events_start_end.csv')"
      ],
      "metadata": {
        "id": "vcGxuzQeDeja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Merge precipitation and runoff data on minute interval"
      ],
      "metadata": {
        "id": "jqPjpH2skZUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_index_s = pd.date_range(\n",
        "    start='2016-10-01 00:00:00',\n",
        "    end='2024-09-30 00:00:00',\n",
        "    freq='1min'\n",
        ")\n",
        "\n",
        "df_time_s = pd.DataFrame({'Date': time_index_s})"
      ],
      "metadata": {
        "id": "v8TpcPwNkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_s = df_time_s.merge(\n",
        "    df_q_s,\n",
        "    on='Date',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "nXGxO2HzkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_s = df_master_s.merge(\n",
        "    df_p_s[['Date', 'Rainfall_mm']],\n",
        "    on='Date',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "jytgsTSvkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create columns with date and time only"
      ],
      "metadata": {
        "id": "fXj2sjFekZUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_s['Date1'] = df_master_s['Date'].dt.date\n",
        "df_master_s['Time'] = df_master_s['Date'].dt.time"
      ],
      "metadata": {
        "id": "kkinZowIkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separate events"
      ],
      "metadata": {
        "id": "QByhWA5ikZUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_s = df_master_s.sort_values('Date')\n",
        "events_time_s = events_time_s.sort_values('start_time')"
      ],
      "metadata": {
        "id": "R02gNrXrkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_s['Date'] = pd.to_datetime(df_master_s['Date'])\n",
        "\n",
        "df_master_s['date'] = df_master_s['Date'].dt.date\n",
        "df_master_s['is_midnight'] = (\n",
        "    (df_master_s['Date'].dt.hour == 0) &\n",
        "    (df_master_s['Date'].dt.minute == 0)\n",
        ")"
      ],
      "metadata": {
        "id": "DEKEcBGQkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_events_s = []\n",
        "\n",
        "for _, ev in events_time_s.iterrows():\n",
        "\n",
        "    start = ev['start_time']\n",
        "    end = ev['end_time']\n",
        "    event_id = ev['Event']\n",
        "\n",
        "     start_rain = start - pd.Timedelta(hours=6)\n",
        "\n",
        "     mask_event = (\n",
        "        (df_master_s['Date'] >= start_rain) &\n",
        "        (df_master_s['Date'] <= end)\n",
        "    )\n",
        "\n",
        "    df_ev_s = df_master_s.loc[mask_event].copy()\n",
        "\n",
        "\n",
        "    df_ev_s.loc[df_ev_s['Date'] < start, 'Volume_mm'] = 0 #aqui está errado porque ele zera o escoamento\n",
        "\n",
        "\n",
        "    days_event_s = pd.date_range(\n",
        "        start_rain.date(),\n",
        "        end.date(),\n",
        "        freq='D'\n",
        "    ).date\n",
        "\n",
        "\n",
        "    mask_daily = (\n",
        "        df_master_s['date'].isin(days_event_s) &\n",
        "        df_master_s['is_midnight'] &\n",
        "        df_master_s['Rainfall_mm'].notna()\n",
        "    )\n",
        "    df_daily_s = df_master_s.loc[mask_daily]\n",
        "\n",
        "\n",
        "    df_event_full_s = (\n",
        "        pd.concat([df_ev_s, df_daily_s])\n",
        "        .drop_duplicates(subset='Date')\n",
        "        .sort_values('Date')\n",
        "    )\n",
        "\n",
        "    df_event_full_s = df_event_full_s.copy()\n",
        "    df_event_full_s['Event'] = event_id\n",
        "\n",
        "    dfs_events_s.append(df_event_full_s)"
      ],
      "metadata": {
        "id": "zx0_b6dlkZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master_events_ext_s = pd.concat(dfs_events_s, ignore_index=True)"
      ],
      "metadata": {
        "id": "UDfDOa2okZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "df_master_events_ext_s.to_csv('RW1S_events_extended.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('RW1S_events_extended.csv')"
      ],
      "metadata": {
        "id": "qx5q9GI6kZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sum event variables"
      ],
      "metadata": {
        "id": "PmAQ6IZwkZUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_sums_s = (\n",
        "    df_master_events_ext_s\n",
        "    .groupby('Event', as_index=False)\n",
        "    .agg(\n",
        "        Volume_event_mm=('Volume_mm', 'sum'),\n",
        "        Rainfall_event_mm=('Rainfall_mm', 'sum')\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "i5Wy80IRkZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_sums_s[\n",
        "    (event_sums_s['Rainfall_event_mm'] == 0) |\n",
        "    (event_sums_s['Volume_event_mm'] == 0)\n",
        "]"
      ],
      "metadata": {
        "id": "8rf3SxLukZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minutes_per_event_s = (\n",
        "    df_master_events_ext_s\n",
        "    .groupby('Event')['Date']\n",
        "    .count()\n",
        "    .reset_index(name='n_minutes')\n",
        ")\n",
        "\n",
        "event_sums_s = event_sums_s.merge(minutes_per_event_s, on='Event')"
      ],
      "metadata": {
        "id": "_7DnlNeYkZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_sums_s"
      ],
      "metadata": {
        "id": "o9zqWa4LkZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "event_sums_s.to_csv('RW1S_sums.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('RW1S_sums.csv')"
      ],
      "metadata": {
        "id": "52sRrunXkZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MC Site"
      ],
      "metadata": {
        "id": "0j8ptYoH7oGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get rainfall data"
      ],
      "metadata": {
        "id": "LtFTsnxh7tj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '1gXo0bOYZxrkakpnB8twwDeczVk4Qg5xMV9HtVop1dP4' #id da planilha do google sheets - retirado do url\n",
        "spreadsheet = gc.open_by_key(id) #para abrir spreadsheet pela chave\n",
        "sheet = spreadsheet.worksheet(\"Precipitation\") #nome da planilha a ser trabalhada\n",
        "rows = sheet.get_all_values()\n",
        "df_p_mc = pd.DataFrame(rows[1:]) #transforma em DataFrame, a partir da linha 1 (linha 0 = cabeçalho)\n",
        "df_p_mc.columns = rows[0] #para transformar a primeira linha"
      ],
      "metadata": {
        "id": "vTbdkrf87tkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_mc.info()"
      ],
      "metadata": {
        "id": "XDb0LWfB7tkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_mc['Rainfall_mm'] = pd.to_numeric(df_p_mc['Rainfall_mm'], errors='coerce') #transformar object em float\n",
        "df_p_mc['Rainfall_mm'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_p_mc['Date'] = pd.to_datetime(df_p_mc['Date'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime"
      ],
      "metadata": {
        "id": "mk66_0Br7tkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p_mc.info()"
      ],
      "metadata": {
        "id": "FVqLq-CB7tkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get start and end of each event"
      ],
      "metadata": {
        "id": "7AbfeQpY7tkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '1gXo0bOYZxrkakpnB8twwDeczVk4Qg5xMV9HtVop1dP4' #id da planilha do google sheets - retirado do url\n",
        "spreadsheet = gc.open_by_key(id) #para abrir spreadsheet pela chave\n",
        "sheet = spreadsheet.worksheet(\"Runoff\") #nome da planilha a ser trabalhada\n",
        "rows = sheet.get_all_values()\n",
        "df_q_mc = pd.DataFrame(rows[1:]) #transforma em DataFrame, a partir da linha 1 (linha 0 = cabeçalho)\n",
        "df_q_mc.columns = rows[0] #para transformar a primeira linha"
      ],
      "metadata": {
        "id": "xRLnsQWY7tkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_mc.info()"
      ],
      "metadata": {
        "id": "csR5kEBX7tkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_mc['Volume_mm'] = pd.to_numeric(df_q_mc['Volume_mm'], errors='coerce') #transformar object em float\n",
        "df_q_mc['Volume_mm'].fillna(0, inplace=True) #preenche NA com 0\n",
        "df_q_mc['Start_event'] = pd.to_datetime(df_q_mc['Start_event'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime\n",
        "df_q_mc['End_event'] = pd.to_datetime(df_q_mc['End_event'], format=\"%m/%d/%Y %H:%M:%S\") #converte string para datetime"
      ],
      "metadata": {
        "collapsed": true,
        "id": "g-8iZ9Vb7tkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_mc.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iuehuSuG7tkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sum rainfall during each event"
      ],
      "metadata": {
        "id": "MqFrs5kp7tkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soma_chuva_evento(df_p_mc, inicio, fim):\n",
        "    mask = (df_p_mc['Date'] >= inicio) & (df_p_mc['Date'] <= fim)\n",
        "    return df_p_mc.loc[mask, 'Rainfall_mm'].sum()"
      ],
      "metadata": {
        "id": "u52MraUz7tkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply function to each event"
      ],
      "metadata": {
        "id": "nMMDQUwR-P33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_q_mc['chuva_total_mm'] = df_q_mc.apply(\n",
        "    lambda row: soma_chuva_evento(\n",
        "        df_p_mc,\n",
        "        row['Start_event'],\n",
        "        row['End_event']\n",
        "    ),\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "PVnBJ0Bk7tkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save\n",
        "df_q_mc.to_csv('MC1_sums.csv', index=True)\n",
        "\n",
        "#Download\n",
        "files.download('MC1_sums.csv')"
      ],
      "metadata": {
        "id": "8huLlEC67tkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}